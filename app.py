import streamlit as st
import requests
from io import BytesIO
from openai import OpenAI
from datetime import datetime
from streamlit_mic_recorder import mic_recorder
import pytz

# =========================
# ê¸°ë³¸ ì„¤ì •
# =========================
korea = pytz.timezone("Asia/Seoul")
now = datetime.now(korea)
cutoff_datetime = korea.localize(datetime(2025, 10, 30, 23, 59, 59))

if now > cutoff_datetime:
    st.error("â›” ì•± ì‚¬ìš©ì‹œê°„ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ê°ì‚¬í•©ë‹ˆë‹¤ğŸ’•")
    st.stop()

st.set_page_config(page_title="ë‚˜ì˜ ê·¸ë¦¼ìƒì (Drawing Assistant)", layout="wide")
st.title("ğŸ–¼ï¸ ë‚˜ì˜ ê·¸ë¦¼ìƒì - My AI Drawing-Box")

# =========================
# ë²„íŠ¼ ìŠ¤íƒ€ì¼
# =========================
st.markdown("""
<style>
div.stButton > button:first-child,
div.stDownloadButton > button:first-child,
div.stFormSubmitButton > button:first-child {
    background-color: #A8E6CF !important;
    color: #004D40 !important;
    font-weight: 900 !important;
    border: none !important;
    border-radius: 10px !important;
    padding: 0.6em 1.2em !important;
    transition: all 0.25s ease-in-out !important;
}
div.stButton > button:hover {
    background-color: #C8F7E6 !important;
    transform: scale(1.03);
}
</style>
""", unsafe_allow_html=True)

# =========================
# OpenAI í´ë¼ì´ì–¸íŠ¸
# =========================
client = OpenAI(api_key=st.secrets["api_key"])

# =========================
# ì˜µì…˜ ì •ì˜
# =========================
def get_options():
    return {
        "style": ["ìŠ¤í‹°ì»¤ ìŠ¤íƒ€ì¼", "ì´ëª¨ì§€ ìŠ¤íƒ€ì¼", "ìˆ˜ì±„í™” ìŠ¤íƒ€ì¼", "ìœ í™” ìŠ¤íƒ€ì¼"],
        "tone": ["ë”°ëœ»í•œ íŒŒìŠ¤í…”í†¤", "ì„ ëª…í•œ ì›ìƒ‰", "ëª½í™˜ì  í¼í”Œ"],
        "mood": ["ëª½í™˜ì ", "ê³ ìš”í•¨", "í¬ë§", "ìŠ¬í””"],
        "viewpoint": ["ì •ë©´", "í•­ê³µ ì‹œì ", "í´ë¡œì¦ˆì—…", "ê´‘ê°"],
        "image_size": ["1024x1024", "1024x1792 (ì„¸ë¡œí˜•)", "1792x1024 (ê°€ë¡œí˜•)"]
    }

options = get_options()

# =========================
# Whisper ìŒì„± ì…ë ¥ + ì£¼ì œ ìë™ ë°˜ì˜
# =========================
st.markdown("### ğŸ™ï¸ ìŒì„±ìœ¼ë¡œ ì£¼ì œ ì…ë ¥í•˜ê¸° (ì„ íƒì‚¬í•­)")
audio_data = mic_recorder(
    start_prompt="ğŸ¤ ë…¹ìŒ ì‹œì‘",
    stop_prompt="ğŸ›‘ ë…¹ìŒ ì¢…ë£Œ",
    just_once=True,
    use_container_width=True,
    callback=None,
    key="voice_input"
)

theme_text = ""

if audio_data and "bytes" in audio_data:
    with st.spinner("ğŸ§ ìŒì„± ì¸ì‹ ì¤‘..."):
        try:
            audio_bytes = audio_data["bytes"]
            transcript = client.audio.transcriptions.create(
                model="gpt-4o-mini-transcribe",
                file=BytesIO(audio_bytes)
            )
            theme_text = transcript.text.strip()
            st.success(f"ğŸ™ï¸ ì¸ì‹ëœ ì£¼ì œ: {theme_text}")
        except Exception as e:
            st.error(f"âŒ Whisper ì¸ì‹ ì‹¤íŒ¨: {e}")

# =========================
# ì£¼ì œ ë° í”„ë¡¬í”„íŠ¸ UI
# =========================
st.markdown("### ğŸ¨ ì£¼ì œ ì…ë ¥ ë˜ëŠ” ìˆ˜ì •")
theme = st.text_input("ğŸ¯ ì£¼ì œ", value=theme_text, placeholder="ì˜ˆ: ê¿ˆì†ì„ ê±·ëŠ” ëŠë‚Œ")

use_ai = st.checkbox("AIê°€ ì‹œê° ìš”ì†Œ ìë™ ì¶”ì²œ", value=True)
style = st.selectbox("ğŸ¨ ìŠ¤íƒ€ì¼", options["style"])
tone = st.selectbox("ğŸ¨ ìƒ‰ìƒ í†¤", options["tone"])
mood = st.multiselect("ğŸ’« ê°ì • / ë¶„ìœ„ê¸°", options["mood"], default=["ëª½í™˜ì "])
viewpoint = st.selectbox("ğŸ“· ì‹œì  / êµ¬ë„", options["viewpoint"])
image_size = st.selectbox("ğŸ–¼ï¸ ì´ë¯¸ì§€ í¬ê¸°", options["image_size"])

if st.button("âœ¨ í”„ë¡¬í”„íŠ¸ ìƒì„±"):
    if not theme.strip():
        st.warning("ì£¼ì œë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ìŒì„±ìœ¼ë¡œ ì¸ì‹ì‹œì¼œì£¼ì„¸ìš”!")
    else:
        with st.spinner("ğŸ§  í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘..."):
            try:
                final_prompt = f"Create a detailed DALLÂ·E 3 prompt about '{theme}' in {style}, {tone}, {', '.join(mood)}, {viewpoint} view."
                st.session_state["dalle_prompt"] = final_prompt
                st.success("âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ!")
            except Exception as e:
                st.error(f"âŒ ì—ëŸ¬: {e}")

# =========================
# ì´ë¯¸ì§€ ìƒì„±
# =========================
if st.session_state.get("dalle_prompt"):
    st.markdown("### ğŸ“ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸")
    st.code(st.session_state["dalle_prompt"])

    if st.button("ğŸ¨ ì´ë¯¸ì§€ ìƒì„±í•˜ê¸°"):
        with st.spinner("ğŸ–¼ï¸ DALLÂ·E ì´ë¯¸ì§€ ìƒì„± ì¤‘..."):
            try:
                size_param = image_size.split(" ")[0]
                image_response = client.images.generate(
                    model="dall-e-3",
                    prompt=st.session_state["dalle_prompt"],
                    size=size_param,
                    n=1
                )
                image_url = image_response.data[0].url
                image_bytes = requests.get(image_url).content
                st.session_state["image_bytes"] = image_bytes
                st.session_state["image_filename"] = f"my_art_box_{size_param}.png"
                st.image(image_bytes, caption="ğŸ‰ ìƒì„±ëœ ì´ë¯¸ì§€")
            except Exception as e:
                st.error(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")

# =========================
# ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
# =========================
if st.session_state.get("image_bytes"):
    st.download_button(
        label="ğŸ“¥ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ",
        data=st.session_state["image_bytes"],
        file_name=st.session_state["image_filename"],
        mime="image/png"
    )
