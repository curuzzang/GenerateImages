import streamlit as st
import requests
from io import BytesIO
from openai import OpenAI
from datetime import datetime
from streamlit_mic_recorder import mic_recorder
from pydub import AudioSegment
import pytz

# =========================
# ê¸°ë³¸ ì„¤ì •
# =========================
korea = pytz.timezone("Asia/Seoul")
now = datetime.now(korea)
cutoff_datetime = korea.localize(datetime(2025, 10, 30, 23, 59, 59))

if now > cutoff_datetime:
    st.error("â›” ì•± ì‚¬ìš©ì‹œê°„ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ê°ì‚¬í•©ë‹ˆë‹¤ğŸ’•")
    st.stop()

st.set_page_config(page_title="ë‚˜ì˜ ê·¸ë¦¼ìƒì (Drawing Assistant)", layout="wide")
st.title("ğŸ–¼ï¸ ë‚˜ì˜ ê·¸ë¦¼ìƒì - My AI Drawing-Box")

# =========================
# ë²„íŠ¼ ìŠ¤íƒ€ì¼
# =========================
st.markdown("""
<style>
div.stButton > button:first-child,
div.stDownloadButton > button:first-child {
    background-color: #A8E6CF !important;
    color: #004D40 !important;
    font-weight: 900 !important;
    border: none !important;
    border-radius: 10px !important;
    padding: 0.6em 1.2em !important;
    transition: all 0.25s ease-in-out !important;
}
div.stButton > button:hover {
    background-color: #C8F7E6 !important;
    transform: scale(1.03);
}
</style>
""", unsafe_allow_html=True)

# =========================
# OpenAI í´ë¼ì´ì–¸íŠ¸
# =========================
client = OpenAI(api_key=st.secrets["api_key"])

# =========================
# ì˜µì…˜ ì •ì˜
# =========================
def get_options():
    return {
        "style": ["ìŠ¤í‹°ì»¤ ìŠ¤íƒ€ì¼", "ì´ëª¨ì§€ ìŠ¤íƒ€ì¼", "ìˆ˜ì±„í™” ìŠ¤íƒ€ì¼", "ìœ í™” ìŠ¤íƒ€ì¼"],
        "tone": ["ë”°ëœ»í•œ íŒŒìŠ¤í…”í†¤", "ì„ ëª…í•œ ì›ìƒ‰", "ëª½í™˜ì  í¼í”Œ"],
        "mood": ["ëª½í™˜ì ", "ê³ ìš”í•¨", "í¬ë§", "ìŠ¬í””"],
        "viewpoint": ["ì •ë©´", "í•­ê³µ ì‹œì ", "í´ë¡œì¦ˆì—…", "ê´‘ê°"],
        "image_size": ["1024x1024", "1024x1792 (ì„¸ë¡œí˜•)", "1792x1024 (ê°€ë¡œí˜•)"]
    }

options = get_options()

# =========================
# ğŸ™ï¸ ìŒì„± ì…ë ¥ + Whisper ë³€í™˜
# =========================
st.markdown("### ğŸ™ï¸ ìŒì„±ìœ¼ë¡œ ì£¼ì œ ì…ë ¥í•˜ê¸° (ì„ íƒì‚¬í•­)")
audio_data = mic_recorder(
    start_prompt="ğŸ¤ ë…¹ìŒ ì‹œì‘",
    stop_prompt="ğŸ›‘ ë…¹ìŒ ì¢…ë£Œ",
    just_once=True,
    use_container_width=True,
    callback=None,
    key="voice_input"
)

theme_text = ""

if audio_data and "bytes" in audio_data:
    with st.spinner("ğŸ§ ìŒì„± ì¸ì‹ ì¤‘..."):
        try:
            # ğŸ”„ WebM â†’ WAV ë³€í™˜
            audio_bytes = audio_data["bytes"]
            webm_audio = AudioSegment.from_file(BytesIO(audio_bytes), format="webm")
            wav_buffer = BytesIO()
            webm_audio.export(wav_buffer, format="wav")
            wav_buffer.seek(0)

            # ğŸ§ Whisper API í˜¸ì¶œ
            transcript = client.audio.transcriptions.create(
                model="gpt-4o-mini-transcribe",
                file=wav_buffer
            )
            theme_text = transcript.text.strip()
            st.success(f"ğŸ™ï¸ ì¸ì‹ëœ ì£¼ì œ: {theme_text}")
        except Exception as e:
            st.error(f"âŒ Whisper ì¸ì‹ ì‹¤íŒ¨: {e}")

# =========================
# ì£¼ì œ ì…ë ¥ ë° ì„ íƒ
# =========================
st.markdown("### ğŸ¨ ì£¼ì œ ì…ë ¥ ë˜ëŠ” ìˆ˜ì •")
theme = st.text_input("ğŸ¯ ì£¼ì œ", value=theme_text, placeholder="ì˜ˆ: ê¿ˆì†ì„ ê±·ëŠ” ëŠë‚Œ")

use_ai = st.checkbox("AIê°€ ì‹œê° ìš”ì†Œ ìë™ ì¶”ì²œ", value=True)
style = st.selectbox("ğŸ¨ ìŠ¤íƒ€ì¼", options["style"])
tone = st.selectbox("ğŸ¨ ìƒ‰ìƒ í†¤", options["tone"])
mood = st.multiselect("ğŸ’« ê°ì • / ë¶„ìœ„ê¸°", options["mood"], default=["ëª½í™˜ì "])
viewpoint = st.selectbox("ğŸ“· ì‹œì  / êµ¬ë„", options["viewpoint"])
image_size = st.selectbox("ğŸ–¼ï¸ ì´ë¯¸ì§€ í¬ê¸°", options["image_size"])

# =========================
# í”„ë¡¬í”„íŠ¸ ìƒì„±
# =========================
if st.button("âœ¨ í”„ë¡¬í”„íŠ¸ ìƒì„±"):
    if not theme.strip():
        st.warning("ì£¼ì œë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ìŒì„±ìœ¼ë¡œ ì¸ì‹ì‹œì¼œì£¼ì„¸ìš”!")
    else:
        with st.spinner("ğŸ§  í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘..."):
            try:
                if use_ai:
                    instruction = f"""
You are a creative assistant. Based on the theme, suggest:
Style, Color tone, Mood(s), and Viewpoint (in Korean).
Theme: {theme}
Format:
Style: ...
Color tone: ...
Mood: ...
Viewpoint: ...
"""
                    ai_response = client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "user", "content": instruction}]
                    )
                    response_text = ai_response.choices[0].message.content.strip()
                    for line in response_text.splitlines():
                        if line.startswith("Style:"):
                            style = line.split(":", 1)[1].strip()
                        elif line.startswith("Color tone:"):
                            tone = line.split(":", 1)[1].strip()
                        elif line.startswith("Mood:"):
                            mood = [m.strip() for m in line.split(":", 1)[1].split(",")]
                        elif line.startswith("Viewpoint:"):
                            viewpoint = line.split(":", 1)[1].strip()

                final_prompt = f"""
Create a vivid English image prompt for DALLÂ·E 3.
Theme: {theme}
Style: {style}
Color tone: {tone}
Mood: {', '.join(mood)}
Viewpoint: {viewpoint}
Only return the prompt.
"""
                prompt_response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": final_prompt}]
                )
                dalle_prompt = prompt_response.choices[0].message.content.strip()[:1000]
                st.session_state["dalle_prompt"] = dalle_prompt
                st.success("âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ!")
                st.code(dalle_prompt)
            except Exception as e:
                st.error(f"âŒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")

# =========================
# DALLÂ·E ì´ë¯¸ì§€ ìƒì„±
# =========================
if st.session_state.get("dalle_prompt"):
    if st.button("ğŸ¨ ì´ë¯¸ì§€ ìƒì„±í•˜ê¸°"):
        with st.spinner("ğŸ–¼ï¸ DALLÂ·E ì´ë¯¸ì§€ ìƒì„± ì¤‘..."):
            try:
                size_param = image_size.split(" ")[0]
                image_response = client.images.generate(
                    model="dall-e-3",
                    prompt=st.session_state["dalle_prompt"],
                    size=size_param,
                    n=1
                )
                image_url = image_response.data[0].url
                image_bytes = requests.get(image_url).content
                st.session_state["image_bytes"] = image_bytes
                st.session_state["image_filename"] = f"my_art_box_{size_param}.png"
                st.image(image_bytes, caption="ğŸ‰ ìƒì„±ëœ ì´ë¯¸ì§€")
                st.success("âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
            except Exception as e:
                st.error(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")

# =========================
# ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
# =========================
if st.session_state.get("image_bytes"):
    st.download_button(
        label="ğŸ“¥ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ",
        data=st.session_state["image_bytes"],
        file_name=st.session_state["image_filename"],
        mime="image/png"
    )
